ğŸ‘‹ Hi, I'm @Rexopia

ğŸš€ **Projects:**
- **HawkLM-demo**: A 316M parameter pre-trained model, trained on Redpajama-1T dataset. Utilizing 3.3 billion pure English tokens, excluding content related to arXiv and GitHub.
- **HawkLM-Chat-demo**: An instruct fine-tuned model based on HawkLM-demo. Leveraged OpenOrca dataset to grant the model preliminary conversational abilities.

ğŸ§  **Research Interests:**
- Information storage and mapping in high-dimensional spaces.
- Reverse/directional extraction of information through LLM compression/learning.
- Enhancement of LLM inferencing abilities.

ğŸ“ **Learning Journey:**
- Iâ€™m currently diving deep into LOADs of exciting areas within AI/NLP!

ğŸ¤ **Collaborations:**
- I'm always open to collaborating on innovative projects. Feel free to reach out if you share similar interests!

ğŸ“« **Contact Me:**
- ğŸ“§ Email: [ruiji.zhang@outlook.com](mailto:ruiji.zhang@outlook.com)
- ğŸ¤– Hugging Face: [Check out my models](https://huggingface.co/Rexopia)

<!---
- ğŸ”— LinkedIn: [Connect with me](https://www.linkedin.com/in/your-link) (Optional)
Rexopia/Rexopia is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
