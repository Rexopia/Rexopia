👋 Hi, I'm @Rexopia

🚀 **Projects:**
- **HawkLM-demo**: A 316M parameter pre-trained model, trained on Redpajama-1T dataset. Utilizing 3.3 billion pure English tokens, excluding content related to arXiv and GitHub.
- **HawkLM-Chat-demo**: An instruct fine-tuned model based on HawkLM-demo. Leveraged OpenOrca dataset to grant the model preliminary conversational abilities.

🧠 **Research Interests:**
- Information storage and mapping in high-dimensional spaces.
- Reverse/directional extraction of information through LLM compression/learning.
- Enhancement of LLM inferencing abilities.

🎓 **Learning Journey:**
- I’m currently diving deep into LOADs of exciting areas within AI/NLP!

🤝 **Collaborations:**
- I'm always open to collaborating on innovative projects. Feel free to reach out if you share similar interests!

📫 **Contact Me:**
- 📧 Email: [ruiji.zhang@outlook.com](mailto:ruiji.zhang@outlook.com)
- 🤖 Hugging Face: [Check out my models](https://huggingface.co/Rexopia)

<!---
- 🔗 LinkedIn: [Connect with me](https://www.linkedin.com/in/your-link) (Optional)
Rexopia/Rexopia is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
